{"cells":[{"cell_type":"markdown","metadata":{"id":"sP4aQJGXUHru"},"source":["Data preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1381,"status":"ok","timestamp":1639548202722,"user":{"displayName":"Beren Chang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597837265257864826"},"user_tz":-480},"id":"Z_irnw6M-tXS","outputId":"93fbe024-da73-45e7-cbea-28d74798470e"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.15.2\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__) # 1.4.1\n","import network, train, utils\n","from layers import SigmoidLayer, ReluLayer, TanhLayer, SoftPlusLayer, TernaryFullyConnectedLayer, BatchNormLayer\n","import os\n","\n","import distutils\n","''' compatible with 1.15\n","if distutils.version.LooseVersion(tf.__version__) <= '2.0':\n","    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n","'''\n","\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","\n","# add empty color dimension\n","# x_train = np.expand_dims(x_train, -1)\n","# x_test = np.expand_dims(x_test, -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-h-pPQYLAjdw"},"outputs":[],"source":["images = np.concatenate([x_train, x_test], axis=0)\n","labels = np.concatenate([y_train, y_test], axis=0)\n","\n","n_train, n_valid, n_test = 55000, 5000, 10000\n","\n","images = images.reshape(70000, 784)\n","y_labels = np.zeros((70000,10), dtype=int)\n","\n","for i in range(70000):\n","  y_labels[i][labels[i]] = 1\n","\n","x_train = images[:n_train]\n","y_train = y_labels[:n_train]\n","x_validate = images[n_train:n_train+n_valid]\n","y_validate = y_labels[n_train:n_train+n_valid]\n","x_test = images[-n_test:]\n","y_test = y_labels[-n_test:]"]},{"cell_type":"markdown","source":["Neural Network Structure"],"metadata":{"id":"SvFKeBcTpzzv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-QK1BmsjATlZ"},"outputs":[],"source":["nn = network.NeuralNetwork(in_size=[None, 784], n_out_classes=10, loss_func=utils.smooth_hinge_loss)\n","\n","nn.reset_graph()\n","\n","# Hidden FC-1\n","nn.add_layer(TernaryFullyConnectedLayer(out_dim=2048))\n","nn.add_layer(BatchNormLayer(axes=[0]))\n","nn.add_layer(SoftplusLayer())\n","\n","# Hidden FC-2\n","nn.add_layer(TernaryFullyConnectedLayer(out_dim=2048))\n","nn.add_layer(BatchNormLayer(axes=[0]))\n","nn.add_layer(SoftplusLayer())\n","\n","# Hidden FC-3\n","nn.add_layer(TernaryFullyConnectedLayer(out_dim=2048))\n","nn.add_layer(BatchNormLayer(axes=[0]))\n","nn.add_layer(SoftplusLayer())\n","\n","# Output SVM layer (linear part)\n","nn.add_layer(TernaryFullyConnectedLayer(out_dim=10))\n","nn.add_layer(BatchNormLayer(axes=[0]))\n","\n","nn.finalize()"]},{"cell_type":"markdown","source":["Initiation"],"metadata":{"id":"7uIpuVaWp5CN"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dpKRBFWaAbe4"},"outputs":[],"source":["data_train = (x_train, y_train)\n","opt = train.Trainer(nn, data_train)\n","\n","opt.set_rho(0.5)\n","opt.set_ema_rates(0.999)"]},{"cell_type":"markdown","source":["Training"],"metadata":{"id":"TN3gnvWysGQl"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TEwpzo09AeCl","outputId":"6e7bc28d-0ca5-4cda-8b5d-0d4a858c8be8","executionInfo":{"status":"ok","timestamp":1639487779374,"user_tz":-480,"elapsed":2567907,"user":{"displayName":"Beren Chang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597837265257864826"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch:  0\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.999, 0.999, 0.999, 0.999]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 1.201993, 0.45\n","Iter: 55 of 550 || Estimated train loss/acc: 0.893175, 0.74\n","Iter: 110 of 550 || Estimated train loss/acc: 0.794007, 0.69\n","Iter: 165 of 550 || Estimated train loss/acc: 0.757418, 0.70\n","Iter: 220 of 550 || Estimated train loss/acc: 0.658218, 0.71\n","Iter: 275 of 550 || Estimated train loss/acc: 0.616286, 0.78\n","Iter: 330 of 550 || Estimated train loss/acc: 0.494251, 0.80\n","Iter: 385 of 550 || Estimated train loss/acc: 0.444862, 0.86\n","Iter: 440 of 550 || Estimated train loss/acc: 0.419389, 0.82\n","Iter: 495 of 550 || Estimated train loss/acc: 0.373392, 0.79\n","Sparsity fraction (ratio of non-zero weights):  0.8491420388972685\n","Train loss/acc:  (0.3251860919865695, 0.84225454677235) Test loss/acc:  (0.33525983572006224, 0.8271999955177307)\n","Epoch:  1\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99905, 0.99905, 0.99905, 0.99905]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.334399, 0.83\n","Iter: 55 of 550 || Estimated train loss/acc: 0.320244, 0.84\n","Iter: 110 of 550 || Estimated train loss/acc: 0.328453, 0.79\n","Iter: 165 of 550 || Estimated train loss/acc: 0.257300, 0.84\n","Iter: 220 of 550 || Estimated train loss/acc: 0.184613, 0.91\n","Iter: 275 of 550 || Estimated train loss/acc: 0.239675, 0.86\n","Iter: 330 of 550 || Estimated train loss/acc: 0.222801, 0.77\n","Iter: 385 of 550 || Estimated train loss/acc: 0.147617, 0.89\n","Iter: 440 of 550 || Estimated train loss/acc: 0.150545, 0.89\n","Iter: 495 of 550 || Estimated train loss/acc: 0.164465, 0.87\n","Sparsity fraction (ratio of non-zero weights):  0.8396474010045648\n","Train loss/acc:  (0.12799148418686607, 0.8814909050681374) Test loss/acc:  (0.14349200904369355, 0.8588000106811523)\n","Epoch:  2\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9990975, 0.9990975, 0.9990975, 0.9990975]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.167532, 0.84\n","Iter: 55 of 550 || Estimated train loss/acc: 0.105498, 0.90\n","Iter: 110 of 550 || Estimated train loss/acc: 0.113244, 0.88\n","Iter: 165 of 550 || Estimated train loss/acc: 0.109737, 0.90\n","Iter: 220 of 550 || Estimated train loss/acc: 0.087804, 0.90\n","Iter: 275 of 550 || Estimated train loss/acc: 0.082931, 0.89\n","Iter: 330 of 550 || Estimated train loss/acc: 0.138141, 0.84\n","Iter: 385 of 550 || Estimated train loss/acc: 0.090616, 0.84\n","Iter: 440 of 550 || Estimated train loss/acc: 0.109449, 0.83\n","Iter: 495 of 550 || Estimated train loss/acc: 0.073246, 0.89\n","Sparsity fraction (ratio of non-zero weights):  0.8253429630394968\n","Train loss/acc:  (0.08049171873114326, 0.8930363587899641) Test loss/acc:  (0.09604763209819794, 0.8719000005722046)\n","Epoch:  3\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99914265, 0.99914265, 0.99914265, 0.99914265]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.070303, 0.93\n","Iter: 55 of 550 || Estimated train loss/acc: 0.092757, 0.85\n","Iter: 110 of 550 || Estimated train loss/acc: 0.090292, 0.87\n","Iter: 165 of 550 || Estimated train loss/acc: 0.058682, 0.93\n","Iter: 220 of 550 || Estimated train loss/acc: 0.062729, 0.92\n","Iter: 275 of 550 || Estimated train loss/acc: 0.080228, 0.86\n","Iter: 330 of 550 || Estimated train loss/acc: 0.070060, 0.91\n","Iter: 385 of 550 || Estimated train loss/acc: 0.087716, 0.87\n","Iter: 440 of 550 || Estimated train loss/acc: 0.068507, 0.89\n","Iter: 495 of 550 || Estimated train loss/acc: 0.050210, 0.95\n","Sparsity fraction (ratio of non-zero weights):  0.8064919136557712\n","Train loss/acc:  (0.06958171318877827, 0.89592726837505) Test loss/acc:  (0.08721635341644288, 0.8698000001907349)\n","Epoch:  4\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9991855, 0.9991855, 0.9991855, 0.9991855]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.094502, 0.84\n","Iter: 55 of 550 || Estimated train loss/acc: 0.077848, 0.88\n","Iter: 110 of 550 || Estimated train loss/acc: 0.104096, 0.86\n","Iter: 165 of 550 || Estimated train loss/acc: 0.052116, 0.93\n","Iter: 220 of 550 || Estimated train loss/acc: 0.064810, 0.92\n","Iter: 275 of 550 || Estimated train loss/acc: 0.072914, 0.90\n","Iter: 330 of 550 || Estimated train loss/acc: 0.065208, 0.90\n","Iter: 385 of 550 || Estimated train loss/acc: 0.081274, 0.88\n","Iter: 440 of 550 || Estimated train loss/acc: 0.062683, 0.89\n","Iter: 495 of 550 || Estimated train loss/acc: 0.056303, 0.90\n","Sparsity fraction (ratio of non-zero weights):  0.7827439995181025\n","Train loss/acc:  (0.059327844665809114, 0.9103090955994346) Test loss/acc:  (0.07751400113105773, 0.8795999956130981)\n","Epoch:  5\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9992262, 0.9992262, 0.9992262, 0.9992262]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.065155, 0.90\n","Iter: 55 of 550 || Estimated train loss/acc: 0.042962, 0.95\n","Iter: 110 of 550 || Estimated train loss/acc: 0.050435, 0.92\n","Iter: 165 of 550 || Estimated train loss/acc: 0.071375, 0.91\n","Iter: 220 of 550 || Estimated train loss/acc: 0.060409, 0.95\n","Iter: 275 of 550 || Estimated train loss/acc: 0.059943, 0.91\n","Iter: 330 of 550 || Estimated train loss/acc: 0.061333, 0.90\n","Iter: 385 of 550 || Estimated train loss/acc: 0.084022, 0.88\n","Iter: 440 of 550 || Estimated train loss/acc: 0.063146, 0.91\n","Iter: 495 of 550 || Estimated train loss/acc: 0.091323, 0.89\n","Sparsity fraction (ratio of non-zero weights):  0.7544374065775024\n","Train loss/acc:  (0.05973111569881439, 0.9094000042568554) Test loss/acc:  (0.07799665957689285, 0.8753999996185303)\n","Epoch:  6\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9992649, 0.9992649, 0.9992649, 0.9992649]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.066882, 0.88\n","Iter: 55 of 550 || Estimated train loss/acc: 0.066356, 0.90\n","Iter: 110 of 550 || Estimated train loss/acc: 0.046662, 0.92\n","Iter: 165 of 550 || Estimated train loss/acc: 0.042923, 0.94\n","Iter: 220 of 550 || Estimated train loss/acc: 0.080216, 0.90\n","Iter: 275 of 550 || Estimated train loss/acc: 0.057490, 0.91\n","Iter: 330 of 550 || Estimated train loss/acc: 0.075017, 0.89\n","Iter: 385 of 550 || Estimated train loss/acc: 0.071106, 0.88\n","Iter: 440 of 550 || Estimated train loss/acc: 0.048513, 0.96\n","Iter: 495 of 550 || Estimated train loss/acc: 0.086133, 0.85\n","Sparsity fraction (ratio of non-zero weights):  0.7251490671014382\n","Train loss/acc:  (0.054884005676616325, 0.9146000044996088) Test loss/acc:  (0.07549011245369912, 0.8801999974250794)\n","Epoch:  7\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9993017, 0.9993017, 0.9993017, 0.9993017]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.065834, 0.89\n","Iter: 55 of 550 || Estimated train loss/acc: 0.055058, 0.93\n","Iter: 110 of 550 || Estimated train loss/acc: 0.064134, 0.90\n","Iter: 165 of 550 || Estimated train loss/acc: 0.059049, 0.89\n","Iter: 220 of 550 || Estimated train loss/acc: 0.053463, 0.92\n","Iter: 275 of 550 || Estimated train loss/acc: 0.048383, 0.94\n","Iter: 330 of 550 || Estimated train loss/acc: 0.089118, 0.87\n","Iter: 385 of 550 || Estimated train loss/acc: 0.049750, 0.95\n","Iter: 440 of 550 || Estimated train loss/acc: 0.061223, 0.88\n","Iter: 495 of 550 || Estimated train loss/acc: 0.075284, 0.90\n","Sparsity fraction (ratio of non-zero weights):  0.6940024501776598\n","Train loss/acc:  (0.05166568260301243, 0.9208363712917674) Test loss/acc:  (0.07290801733732223, 0.8837999963760376)\n","Epoch:  8\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9993366, 0.9993366, 0.9993366, 0.9993366]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.054604, 0.92\n","Iter: 55 of 550 || Estimated train loss/acc: 0.049999, 0.93\n","Iter: 110 of 550 || Estimated train loss/acc: 0.036628, 0.95\n","Iter: 165 of 550 || Estimated train loss/acc: 0.043467, 0.94\n","Iter: 220 of 550 || Estimated train loss/acc: 0.050486, 0.91\n","Iter: 275 of 550 || Estimated train loss/acc: 0.080925, 0.92\n","Iter: 330 of 550 || Estimated train loss/acc: 0.032645, 0.97\n","Iter: 385 of 550 || Estimated train loss/acc: 0.063887, 0.89\n","Iter: 440 of 550 || Estimated train loss/acc: 0.046000, 0.93\n","Iter: 495 of 550 || Estimated train loss/acc: 0.070573, 0.90\n","Sparsity fraction (ratio of non-zero weights):  0.6659356092353587\n","Train loss/acc:  (0.052348093742674046, 0.9196909165382385) Test loss/acc:  (0.07375340431928634, 0.884399995803833)\n","Epoch:  9\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99936974, 0.99936974, 0.99936974, 0.99936974]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.033206, 0.95\n","Iter: 55 of 550 || Estimated train loss/acc: 0.048723, 0.92\n","Iter: 110 of 550 || Estimated train loss/acc: 0.042134, 0.94\n","Iter: 165 of 550 || Estimated train loss/acc: 0.058567, 0.91\n","Iter: 220 of 550 || Estimated train loss/acc: 0.037529, 0.93\n","Iter: 275 of 550 || Estimated train loss/acc: 0.060095, 0.90\n","Iter: 330 of 550 || Estimated train loss/acc: 0.069195, 0.89\n","Iter: 385 of 550 || Estimated train loss/acc: 0.047176, 0.95\n","Iter: 440 of 550 || Estimated train loss/acc: 0.053972, 0.94\n","Iter: 495 of 550 || Estimated train loss/acc: 0.052560, 0.91\n","Sparsity fraction (ratio of non-zero weights):  0.640175932489667\n","Train loss/acc:  (0.05153077485886487, 0.9203636431694031) Test loss/acc:  (0.07546356305480004, 0.8812999939918518)\n","Epoch:  10\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9994013, 0.9994013, 0.9994013, 0.9994013]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.073075, 0.89\n","Iter: 55 of 550 || Estimated train loss/acc: 0.069337, 0.89\n","Iter: 110 of 550 || Estimated train loss/acc: 0.061030, 0.91\n","Iter: 165 of 550 || Estimated train loss/acc: 0.052101, 0.93\n","Iter: 220 of 550 || Estimated train loss/acc: 0.050535, 0.89\n","Iter: 275 of 550 || Estimated train loss/acc: 0.055951, 0.92\n","Iter: 330 of 550 || Estimated train loss/acc: 0.039535, 0.94\n","Iter: 385 of 550 || Estimated train loss/acc: 0.064814, 0.89\n","Iter: 440 of 550 || Estimated train loss/acc: 0.060973, 0.90\n","Iter: 495 of 550 || Estimated train loss/acc: 0.052514, 0.90\n","Sparsity fraction (ratio of non-zero weights):  0.6151217489369731\n","Train loss/acc:  (0.05307488243688237, 0.9196545533700423) Test loss/acc:  (0.07592978835105896, 0.8783999967575074)\n","Epoch:  11\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9994312, 0.9994312, 0.9994312, 0.9994312]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.057197, 0.93\n","Iter: 55 of 550 || Estimated train loss/acc: 0.039920, 0.96\n","Iter: 110 of 550 || Estimated train loss/acc: 0.069032, 0.89\n","Iter: 165 of 550 || Estimated train loss/acc: 0.052682, 0.90\n","Iter: 220 of 550 || Estimated train loss/acc: 0.039228, 0.96\n","Iter: 275 of 550 || Estimated train loss/acc: 0.050675, 0.94\n","Iter: 330 of 550 || Estimated train loss/acc: 0.060021, 0.93\n","Iter: 385 of 550 || Estimated train loss/acc: 0.033333, 0.95\n","Iter: 440 of 550 || Estimated train loss/acc: 0.074219, 0.87\n","Iter: 495 of 550 || Estimated train loss/acc: 0.080589, 0.88\n","Sparsity fraction (ratio of non-zero weights):  0.5929808912471373\n","Train loss/acc:  (0.048914122635667974, 0.9281090998649597) Test loss/acc:  (0.0743664701282978, 0.8864000034332276)\n","Epoch:  12\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9994596, 0.9994596, 0.9994596, 0.9994596]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.044630, 0.94\n","Iter: 55 of 550 || Estimated train loss/acc: 0.064153, 0.90\n","Iter: 110 of 550 || Estimated train loss/acc: 0.048141, 0.94\n","Iter: 165 of 550 || Estimated train loss/acc: 0.043073, 0.95\n","Iter: 220 of 550 || Estimated train loss/acc: 0.075847, 0.88\n","Iter: 275 of 550 || Estimated train loss/acc: 0.044422, 0.95\n","Iter: 330 of 550 || Estimated train loss/acc: 0.049449, 0.91\n","Iter: 385 of 550 || Estimated train loss/acc: 0.065889, 0.90\n","Iter: 440 of 550 || Estimated train loss/acc: 0.073737, 0.90\n","Iter: 495 of 550 || Estimated train loss/acc: 0.065665, 0.90\n","Sparsity fraction (ratio of non-zero weights):  0.5704907775265013\n","Train loss/acc:  (0.047090774733911864, 0.9287272789261558) Test loss/acc:  (0.07395413637161255, 0.8855999970436096)\n","Epoch:  13\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9994866, 0.9994866, 0.9994866, 0.9994866]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.069787, 0.91\n","Iter: 55 of 550 || Estimated train loss/acc: 0.075986, 0.86\n","Iter: 110 of 550 || Estimated train loss/acc: 0.045403, 0.93\n","Iter: 165 of 550 || Estimated train loss/acc: 0.048912, 0.91\n","Iter: 220 of 550 || Estimated train loss/acc: 0.087023, 0.84\n","Iter: 275 of 550 || Estimated train loss/acc: 0.050223, 0.91\n","Iter: 330 of 550 || Estimated train loss/acc: 0.048841, 0.93\n","Iter: 385 of 550 || Estimated train loss/acc: 0.063845, 0.91\n","Iter: 440 of 550 || Estimated train loss/acc: 0.058523, 0.94\n","Iter: 495 of 550 || Estimated train loss/acc: 0.036718, 0.97\n","Sparsity fraction (ratio of non-zero weights):  0.5528185420445619\n","Train loss/acc:  (0.04532123412598263, 0.9306909142840992) Test loss/acc:  (0.0711033982038498, 0.8918000054359436)\n","Epoch:  14\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9995123, 0.9995123, 0.9995123, 0.9995123]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.054906, 0.95\n","Iter: 55 of 550 || Estimated train loss/acc: 0.037112, 0.98\n","Iter: 110 of 550 || Estimated train loss/acc: 0.033242, 0.97\n","Iter: 165 of 550 || Estimated train loss/acc: 0.068012, 0.87\n","Iter: 220 of 550 || Estimated train loss/acc: 0.042524, 0.92\n","Iter: 275 of 550 || Estimated train loss/acc: 0.037013, 0.95\n","Iter: 330 of 550 || Estimated train loss/acc: 0.035765, 0.94\n","Iter: 385 of 550 || Estimated train loss/acc: 0.060223, 0.89\n","Iter: 440 of 550 || Estimated train loss/acc: 0.047619, 0.94\n","Iter: 495 of 550 || Estimated train loss/acc: 0.050442, 0.93\n","Sparsity fraction (ratio of non-zero weights):  0.5329091531408908\n","Train loss/acc:  (0.04391058247197758, 0.9345090933279557) Test loss/acc:  (0.0715511479973793, 0.8880000042915345)\n","Epoch:  15\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9995367, 0.9995367, 0.9995367, 0.9995367]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.032658, 0.97\n","Iter: 55 of 550 || Estimated train loss/acc: 0.036672, 0.94\n","Iter: 110 of 550 || Estimated train loss/acc: 0.040774, 0.94\n","Iter: 165 of 550 || Estimated train loss/acc: 0.050492, 0.93\n","Iter: 220 of 550 || Estimated train loss/acc: 0.039626, 0.94\n","Iter: 275 of 550 || Estimated train loss/acc: 0.039764, 0.95\n","Iter: 330 of 550 || Estimated train loss/acc: 0.062130, 0.93\n","Iter: 385 of 550 || Estimated train loss/acc: 0.051859, 0.92\n","Iter: 440 of 550 || Estimated train loss/acc: 0.036068, 0.95\n","Iter: 495 of 550 || Estimated train loss/acc: 0.036813, 0.97\n","Sparsity fraction (ratio of non-zero weights):  0.5173574861863356\n","Train loss/acc:  (0.043529861772602256, 0.9344727297262712) Test loss/acc:  (0.07385419011116028, 0.8857999968528748)\n","Epoch:  16\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9995599, 0.9995599, 0.9995599, 0.9995599]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.055462, 0.91\n","Iter: 55 of 550 || Estimated train loss/acc: 0.065049, 0.89\n","Iter: 110 of 550 || Estimated train loss/acc: 0.033116, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.066188, 0.90\n","Iter: 220 of 550 || Estimated train loss/acc: 0.043837, 0.97\n","Iter: 275 of 550 || Estimated train loss/acc: 0.042691, 0.95\n","Iter: 330 of 550 || Estimated train loss/acc: 0.040770, 0.93\n","Iter: 385 of 550 || Estimated train loss/acc: 0.042637, 0.94\n","Iter: 440 of 550 || Estimated train loss/acc: 0.059232, 0.90\n","Iter: 495 of 550 || Estimated train loss/acc: 0.062600, 0.92\n","Sparsity fraction (ratio of non-zero weights):  0.5009942128415319\n","Train loss/acc:  (0.04005406194112517, 0.9395636348290877) Test loss/acc:  (0.07123947337269783, 0.8909000015258789)\n","Epoch:  17\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9995819, 0.9995819, 0.9995819, 0.9995819]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.027451, 0.98\n","Iter: 55 of 550 || Estimated train loss/acc: 0.029125, 0.96\n","Iter: 110 of 550 || Estimated train loss/acc: 0.042227, 0.95\n","Iter: 165 of 550 || Estimated train loss/acc: 0.046769, 0.92\n","Iter: 220 of 550 || Estimated train loss/acc: 0.067225, 0.88\n","Iter: 275 of 550 || Estimated train loss/acc: 0.049049, 0.95\n","Iter: 330 of 550 || Estimated train loss/acc: 0.047646, 0.95\n","Iter: 385 of 550 || Estimated train loss/acc: 0.036773, 0.96\n","Iter: 440 of 550 || Estimated train loss/acc: 0.035935, 0.94\n","Iter: 495 of 550 || Estimated train loss/acc: 0.063198, 0.90\n","Sparsity fraction (ratio of non-zero weights):  0.48921624632942085\n","Train loss/acc:  (0.047611108869314196, 0.9248181891441345) Test loss/acc:  (0.08301072031259536, 0.8765000009536743)\n","Epoch:  18\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9996028, 0.9996028, 0.9996028, 0.9996028]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.039606, 0.94\n","Iter: 55 of 550 || Estimated train loss/acc: 0.033225, 0.97\n","Iter: 110 of 550 || Estimated train loss/acc: 0.033626, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.042634, 0.93\n","Iter: 220 of 550 || Estimated train loss/acc: 0.042036, 0.92\n","Iter: 275 of 550 || Estimated train loss/acc: 0.038954, 0.93\n","Iter: 330 of 550 || Estimated train loss/acc: 0.045468, 0.91\n","Iter: 385 of 550 || Estimated train loss/acc: 0.030002, 0.98\n","Iter: 440 of 550 || Estimated train loss/acc: 0.030403, 0.97\n","Iter: 495 of 550 || Estimated train loss/acc: 0.066338, 0.91\n","Sparsity fraction (ratio of non-zero weights):  0.47480380028858005\n","Train loss/acc:  (0.03711119566451419, 0.9449818114800886) Test loss/acc:  (0.07178283736109733, 0.8914999961853027)\n","Epoch:  19\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99962264, 0.99962264, 0.99962264, 0.99962264]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.041580, 0.94\n","Iter: 55 of 550 || Estimated train loss/acc: 0.025859, 0.96\n","Iter: 110 of 550 || Estimated train loss/acc: 0.041775, 0.93\n","Iter: 165 of 550 || Estimated train loss/acc: 0.063645, 0.91\n","Iter: 220 of 550 || Estimated train loss/acc: 0.045541, 0.91\n","Iter: 275 of 550 || Estimated train loss/acc: 0.037929, 0.93\n","Iter: 330 of 550 || Estimated train loss/acc: 0.036515, 0.94\n","Iter: 385 of 550 || Estimated train loss/acc: 0.057205, 0.90\n","Iter: 440 of 550 || Estimated train loss/acc: 0.036756, 0.94\n","Iter: 495 of 550 || Estimated train loss/acc: 0.050160, 0.94\n","Sparsity fraction (ratio of non-zero weights):  0.46454223524657556\n","Train loss/acc:  (0.03999425679445267, 0.9425454506007108) Test loss/acc:  (0.07613831415772437, 0.8893999981880188)\n","Epoch:  20\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99964154, 0.99964154, 0.99964154, 0.99964154]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.057391, 0.90\n","Iter: 55 of 550 || Estimated train loss/acc: 0.039375, 0.94\n","Iter: 110 of 550 || Estimated train loss/acc: 0.032201, 0.93\n","Iter: 165 of 550 || Estimated train loss/acc: 0.025849, 0.96\n","Iter: 220 of 550 || Estimated train loss/acc: 0.032561, 0.96\n","Iter: 275 of 550 || Estimated train loss/acc: 0.057611, 0.92\n","Iter: 330 of 550 || Estimated train loss/acc: 0.028123, 0.98\n","Iter: 385 of 550 || Estimated train loss/acc: 0.022744, 0.99\n","Iter: 440 of 550 || Estimated train loss/acc: 0.040922, 0.93\n","Iter: 495 of 550 || Estimated train loss/acc: 0.026631, 0.96\n","Sparsity fraction (ratio of non-zero weights):  0.4531221015838392\n","Train loss/acc:  (0.03263616260479797, 0.9529636257345027) Test loss/acc:  (0.07341976314783097, 0.8917999982833862)\n","Epoch:  21\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9996595, 0.9996595, 0.9996595, 0.9996595]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.038146, 0.94\n","Iter: 55 of 550 || Estimated train loss/acc: 0.035919, 0.96\n","Iter: 110 of 550 || Estimated train loss/acc: 0.034657, 0.96\n","Iter: 165 of 550 || Estimated train loss/acc: 0.032434, 0.95\n","Iter: 220 of 550 || Estimated train loss/acc: 0.054734, 0.94\n","Iter: 275 of 550 || Estimated train loss/acc: 0.028755, 0.96\n","Iter: 330 of 550 || Estimated train loss/acc: 0.029034, 0.95\n","Iter: 385 of 550 || Estimated train loss/acc: 0.031435, 0.98\n","Iter: 440 of 550 || Estimated train loss/acc: 0.033419, 0.96\n","Iter: 495 of 550 || Estimated train loss/acc: 0.052977, 0.90\n","Sparsity fraction (ratio of non-zero weights):  0.4393500247530973\n","Train loss/acc:  (0.03542942663485354, 0.9486545374176719) Test loss/acc:  (0.07496721103787422, 0.8899000000953674)\n","Epoch:  22\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9996765, 0.9996765, 0.9996765, 0.9996765]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.048190, 0.94\n","Iter: 55 of 550 || Estimated train loss/acc: 0.025316, 0.96\n","Iter: 110 of 550 || Estimated train loss/acc: 0.034269, 0.95\n","Iter: 165 of 550 || Estimated train loss/acc: 0.024057, 0.96\n","Iter: 220 of 550 || Estimated train loss/acc: 0.035604, 0.95\n","Iter: 275 of 550 || Estimated train loss/acc: 0.036005, 0.94\n","Iter: 330 of 550 || Estimated train loss/acc: 0.047162, 0.94\n","Iter: 385 of 550 || Estimated train loss/acc: 0.020361, 0.98\n","Iter: 440 of 550 || Estimated train loss/acc: 0.025875, 0.98\n","Iter: 495 of 550 || Estimated train loss/acc: 0.043481, 0.94\n","Sparsity fraction (ratio of non-zero weights):  0.42984611192867916\n","Train loss/acc:  (0.03184164752337065, 0.9526908972046592) Test loss/acc:  (0.07227309405803681, 0.8948999953269958)\n","Epoch:  23\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9996927, 0.9996927, 0.9996927, 0.9996927]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.027779, 0.94\n","Iter: 55 of 550 || Estimated train loss/acc: 0.022457, 0.97\n","Iter: 110 of 550 || Estimated train loss/acc: 0.055120, 0.91\n","Iter: 165 of 550 || Estimated train loss/acc: 0.040553, 0.91\n","Iter: 220 of 550 || Estimated train loss/acc: 0.026702, 0.96\n","Iter: 275 of 550 || Estimated train loss/acc: 0.022374, 0.96\n","Iter: 330 of 550 || Estimated train loss/acc: 0.041066, 0.95\n","Iter: 385 of 550 || Estimated train loss/acc: 0.055952, 0.93\n","Iter: 440 of 550 || Estimated train loss/acc: 0.029497, 0.95\n","Iter: 495 of 550 || Estimated train loss/acc: 0.048950, 0.94\n","Sparsity fraction (ratio of non-zero weights):  0.41932734205988054\n","Train loss/acc:  (0.032649653255939486, 0.9521272605115717) Test loss/acc:  (0.07553485184907913, 0.8916999912261963)\n","Epoch:  24\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99970806, 0.99970806, 0.99970806, 0.99970806]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.027711, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.036536, 0.95\n","Iter: 110 of 550 || Estimated train loss/acc: 0.043271, 0.93\n","Iter: 165 of 550 || Estimated train loss/acc: 0.042370, 0.94\n","Iter: 220 of 550 || Estimated train loss/acc: 0.016750, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.029366, 0.99\n","Iter: 330 of 550 || Estimated train loss/acc: 0.045334, 0.92\n","Iter: 385 of 550 || Estimated train loss/acc: 0.037660, 0.95\n","Iter: 440 of 550 || Estimated train loss/acc: 0.050622, 0.93\n","Iter: 495 of 550 || Estimated train loss/acc: 0.041845, 0.95\n","Sparsity fraction (ratio of non-zero weights):  0.4101451596624643\n","Train loss/acc:  (0.028755927912213586, 0.9586181712150573) Test loss/acc:  (0.07409245073795319, 0.8935000014305114)\n","Epoch:  25\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99972266, 0.99972266, 0.99972266, 0.99972266]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.032784, 0.96\n","Iter: 55 of 550 || Estimated train loss/acc: 0.039443, 0.93\n","Iter: 110 of 550 || Estimated train loss/acc: 0.033560, 0.96\n","Iter: 165 of 550 || Estimated train loss/acc: 0.039329, 0.95\n","Iter: 220 of 550 || Estimated train loss/acc: 0.030616, 0.96\n","Iter: 275 of 550 || Estimated train loss/acc: 0.037450, 0.95\n","Iter: 330 of 550 || Estimated train loss/acc: 0.049142, 0.92\n","Iter: 385 of 550 || Estimated train loss/acc: 0.028681, 0.94\n","Iter: 440 of 550 || Estimated train loss/acc: 0.038535, 0.96\n","Iter: 495 of 550 || Estimated train loss/acc: 0.029994, 0.96\n","Sparsity fraction (ratio of non-zero weights):  0.4031692142477312\n","Train loss/acc:  (0.029572780321944842, 0.9573636239225214) Test loss/acc:  (0.07534980580210686, 0.8911999988555909)\n","Epoch:  26\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99973655, 0.99973655, 0.99973655, 0.99973655]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.032112, 0.95\n","Iter: 55 of 550 || Estimated train loss/acc: 0.022870, 0.97\n","Iter: 110 of 550 || Estimated train loss/acc: 0.016112, 0.99\n","Iter: 165 of 550 || Estimated train loss/acc: 0.028193, 0.95\n","Iter: 220 of 550 || Estimated train loss/acc: 0.035769, 0.93\n","Iter: 275 of 550 || Estimated train loss/acc: 0.025146, 0.96\n","Iter: 330 of 550 || Estimated train loss/acc: 0.027964, 0.96\n","Iter: 385 of 550 || Estimated train loss/acc: 0.046560, 0.94\n","Iter: 440 of 550 || Estimated train loss/acc: 0.030306, 0.97\n","Iter: 495 of 550 || Estimated train loss/acc: 0.039273, 0.95\n","Sparsity fraction (ratio of non-zero weights):  0.394993012884775\n","Train loss/acc:  (0.02749494771388444, 0.9611454443498091) Test loss/acc:  (0.0761912277340889, 0.8901999998092651)\n","Epoch:  27\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9997497, 0.9997497, 0.9997497, 0.9997497]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.016701, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.040805, 0.94\n","Iter: 110 of 550 || Estimated train loss/acc: 0.014818, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.025361, 0.98\n","Iter: 220 of 550 || Estimated train loss/acc: 0.026701, 0.98\n","Iter: 275 of 550 || Estimated train loss/acc: 0.030585, 0.96\n","Iter: 330 of 550 || Estimated train loss/acc: 0.037085, 0.95\n","Iter: 385 of 550 || Estimated train loss/acc: 0.023328, 0.96\n","Iter: 440 of 550 || Estimated train loss/acc: 0.025729, 0.97\n","Iter: 495 of 550 || Estimated train loss/acc: 0.019514, 0.99\n","Sparsity fraction (ratio of non-zero weights):  0.38622012424818203\n","Train loss/acc:  (0.026028505489230157, 0.9627090831236406) Test loss/acc:  (0.0789423444867134, 0.8916999936103821)\n","Epoch:  28\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99976224, 0.99976224, 0.99976224, 0.99976224]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.031878, 0.96\n","Iter: 55 of 550 || Estimated train loss/acc: 0.016332, 0.98\n","Iter: 110 of 550 || Estimated train loss/acc: 0.037299, 0.95\n","Iter: 165 of 550 || Estimated train loss/acc: 0.021006, 0.98\n","Iter: 220 of 550 || Estimated train loss/acc: 0.039577, 0.93\n","Iter: 275 of 550 || Estimated train loss/acc: 0.026588, 0.96\n","Iter: 330 of 550 || Estimated train loss/acc: 0.026870, 0.96\n","Iter: 385 of 550 || Estimated train loss/acc: 0.012004, 0.99\n","Iter: 440 of 550 || Estimated train loss/acc: 0.037846, 0.97\n","Iter: 495 of 550 || Estimated train loss/acc: 0.018679, 0.97\n","Sparsity fraction (ratio of non-zero weights):  0.37858406299453834\n","Train loss/acc:  (0.023402487175031142, 0.9673636334592646) Test loss/acc:  (0.07642538040876388, 0.8917999982833862)\n","Epoch:  29\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9997741, 0.9997741, 0.9997741, 0.9997741]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.023929, 0.98\n","Iter: 55 of 550 || Estimated train loss/acc: 0.035859, 0.96\n","Iter: 110 of 550 || Estimated train loss/acc: 0.021772, 0.97\n","Iter: 165 of 550 || Estimated train loss/acc: 0.031739, 0.96\n","Iter: 220 of 550 || Estimated train loss/acc: 0.029443, 0.97\n","Iter: 275 of 550 || Estimated train loss/acc: 0.035700, 0.93\n","Iter: 330 of 550 || Estimated train loss/acc: 0.023209, 0.97\n","Iter: 385 of 550 || Estimated train loss/acc: 0.035389, 0.95\n","Iter: 440 of 550 || Estimated train loss/acc: 0.017037, 0.99\n","Iter: 495 of 550 || Estimated train loss/acc: 0.052160, 0.91\n","Sparsity fraction (ratio of non-zero weights):  0.3691847674106425\n","Train loss/acc:  (0.023803694180466912, 0.9664909048513932) Test loss/acc:  (0.08019469097256661, 0.891100001335144)\n","Epoch:  30\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9997854, 0.9997854, 0.9997854, 0.9997854]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.019936, 0.96\n","Iter: 55 of 550 || Estimated train loss/acc: 0.026457, 0.94\n","Iter: 110 of 550 || Estimated train loss/acc: 0.020488, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.018583, 0.97\n","Iter: 220 of 550 || Estimated train loss/acc: 0.016417, 0.96\n","Iter: 275 of 550 || Estimated train loss/acc: 0.023401, 0.96\n","Iter: 330 of 550 || Estimated train loss/acc: 0.022519, 0.98\n","Iter: 385 of 550 || Estimated train loss/acc: 0.022978, 0.97\n","Iter: 440 of 550 || Estimated train loss/acc: 0.021280, 0.99\n","Iter: 495 of 550 || Estimated train loss/acc: 0.033723, 0.95\n","Sparsity fraction (ratio of non-zero weights):  0.3649153069084877\n","Train loss/acc:  (0.024397981309077957, 0.9663999958471818) Test loss/acc:  (0.08303209960460663, 0.8920999979972839)\n","Epoch:  31\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99979615, 0.99979615, 0.99979615, 0.99979615]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.018825, 0.98\n","Iter: 55 of 550 || Estimated train loss/acc: 0.019397, 0.96\n","Iter: 110 of 550 || Estimated train loss/acc: 0.029208, 0.97\n","Iter: 165 of 550 || Estimated train loss/acc: 0.016917, 0.97\n","Iter: 220 of 550 || Estimated train loss/acc: 0.025252, 0.97\n","Iter: 275 of 550 || Estimated train loss/acc: 0.022628, 0.97\n","Iter: 330 of 550 || Estimated train loss/acc: 0.016118, 0.99\n","Iter: 385 of 550 || Estimated train loss/acc: 0.039558, 0.92\n","Iter: 440 of 550 || Estimated train loss/acc: 0.050676, 0.93\n","Iter: 495 of 550 || Estimated train loss/acc: 0.028773, 0.97\n","Sparsity fraction (ratio of non-zero weights):  0.35848847734343614\n","Train loss/acc:  (0.020939027985388582, 0.9702181852947582) Test loss/acc:  (0.08223262250423431, 0.8897999954223633)\n","Epoch:  32\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99980634, 0.99980634, 0.99980634, 0.99980634]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.032012, 0.98\n","Iter: 55 of 550 || Estimated train loss/acc: 0.012963, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.011264, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.013122, 0.99\n","Iter: 220 of 550 || Estimated train loss/acc: 0.014021, 0.98\n","Iter: 275 of 550 || Estimated train loss/acc: 0.019998, 0.98\n","Iter: 330 of 550 || Estimated train loss/acc: 0.032921, 0.97\n","Iter: 385 of 550 || Estimated train loss/acc: 0.004838, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.035142, 0.95\n","Iter: 495 of 550 || Estimated train loss/acc: 0.024961, 0.96\n","Sparsity fraction (ratio of non-zero weights):  0.3525906180774602\n","Train loss/acc:  (0.020270916494456205, 0.9719454622268677) Test loss/acc:  (0.0838272026181221, 0.8925999975204468)\n","Epoch:  33\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.999816, 0.999816, 0.999816, 0.999816]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.020146, 0.98\n","Iter: 55 of 550 || Estimated train loss/acc: 0.009187, 0.99\n","Iter: 110 of 550 || Estimated train loss/acc: 0.023458, 0.97\n","Iter: 165 of 550 || Estimated train loss/acc: 0.020694, 0.98\n","Iter: 220 of 550 || Estimated train loss/acc: 0.017835, 0.98\n","Iter: 275 of 550 || Estimated train loss/acc: 0.011319, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.016759, 0.97\n","Iter: 385 of 550 || Estimated train loss/acc: 0.024562, 0.96\n","Iter: 440 of 550 || Estimated train loss/acc: 0.048511, 0.94\n","Iter: 495 of 550 || Estimated train loss/acc: 0.017852, 0.98\n","Sparsity fraction (ratio of non-zero weights):  0.3474016428397328\n","Train loss/acc:  (0.018024185333739628, 0.9757454685731367) Test loss/acc:  (0.08501021906733514, 0.8938000011444092)\n","Epoch:  34\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9998252, 0.9998252, 0.9998252, 0.9998252]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.014288, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.024102, 0.99\n","Iter: 110 of 550 || Estimated train loss/acc: 0.032324, 0.93\n","Iter: 165 of 550 || Estimated train loss/acc: 0.021139, 0.96\n","Iter: 220 of 550 || Estimated train loss/acc: 0.016610, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.034841, 0.97\n","Iter: 330 of 550 || Estimated train loss/acc: 0.011570, 0.99\n","Iter: 385 of 550 || Estimated train loss/acc: 0.018418, 0.98\n","Iter: 440 of 550 || Estimated train loss/acc: 0.016086, 0.99\n","Iter: 495 of 550 || Estimated train loss/acc: 0.065170, 0.93\n","Sparsity fraction (ratio of non-zero weights):  0.3380038432125651\n","Train loss/acc:  (0.016014507460323246, 0.9788000137155706) Test loss/acc:  (0.08282777681946754, 0.8956999993324279)\n","Epoch:  35\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99983394, 0.99983394, 0.99983394, 0.99983394]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.012692, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.017606, 0.98\n","Iter: 110 of 550 || Estimated train loss/acc: 0.025115, 0.96\n","Iter: 165 of 550 || Estimated train loss/acc: 0.025186, 0.95\n","Iter: 220 of 550 || Estimated train loss/acc: 0.021434, 0.96\n","Iter: 275 of 550 || Estimated train loss/acc: 0.020772, 0.97\n","Iter: 330 of 550 || Estimated train loss/acc: 0.011633, 0.99\n","Iter: 385 of 550 || Estimated train loss/acc: 0.014677, 0.97\n","Iter: 440 of 550 || Estimated train loss/acc: 0.028400, 0.96\n","Iter: 495 of 550 || Estimated train loss/acc: 0.020404, 0.97\n","Sparsity fraction (ratio of non-zero weights):  0.3330939137698628\n","Train loss/acc:  (0.016510127437385645, 0.9778181977705522) Test loss/acc:  (0.0862544047832489, 0.8949000000953674)\n","Epoch:  36\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9998422, 0.9998422, 0.9998422, 0.9998422]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.011106, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.012740, 0.99\n","Iter: 110 of 550 || Estimated train loss/acc: 0.017824, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.010354, 0.99\n","Iter: 220 of 550 || Estimated train loss/acc: 0.023193, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.013407, 0.99\n","Iter: 330 of 550 || Estimated train loss/acc: 0.016903, 0.99\n","Iter: 385 of 550 || Estimated train loss/acc: 0.031145, 0.98\n","Iter: 440 of 550 || Estimated train loss/acc: 0.015170, 0.98\n","Iter: 495 of 550 || Estimated train loss/acc: 0.016269, 0.98\n","Sparsity fraction (ratio of non-zero weights):  0.3260508497632599\n","Train loss/acc:  (0.015870986093174326, 0.9789818338914351) Test loss/acc:  (0.09055196106433869, 0.8921999955177307)\n","Epoch:  37\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9998501, 0.9998501, 0.9998501, 0.9998501]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.019540, 0.98\n","Iter: 55 of 550 || Estimated train loss/acc: 0.018400, 0.97\n","Iter: 110 of 550 || Estimated train loss/acc: 0.015436, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.020043, 0.96\n","Iter: 220 of 550 || Estimated train loss/acc: 0.008131, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.029184, 0.93\n","Iter: 330 of 550 || Estimated train loss/acc: 0.022467, 0.97\n","Iter: 385 of 550 || Estimated train loss/acc: 0.013761, 0.98\n","Iter: 440 of 550 || Estimated train loss/acc: 0.011945, 0.99\n","Iter: 495 of 550 || Estimated train loss/acc: 0.019382, 0.98\n","Sparsity fraction (ratio of non-zero weights):  0.20230361379264125\n","Train loss/acc:  (0.014250017340210351, 0.981763652454723) Test loss/acc:  (0.09418749049305916, 0.8915999960899353)\n","Epoch:  38\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9998576, 0.9998576, 0.9998576, 0.9998576]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.016778, 0.98\n","Iter: 55 of 550 || Estimated train loss/acc: 0.022332, 0.97\n","Iter: 110 of 550 || Estimated train loss/acc: 0.011773, 0.99\n","Iter: 165 of 550 || Estimated train loss/acc: 0.016555, 0.97\n","Iter: 220 of 550 || Estimated train loss/acc: 0.024949, 0.96\n","Iter: 275 of 550 || Estimated train loss/acc: 0.010123, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.013301, 0.98\n","Iter: 385 of 550 || Estimated train loss/acc: 0.009254, 0.98\n","Iter: 440 of 550 || Estimated train loss/acc: 0.009712, 0.99\n","Iter: 495 of 550 || Estimated train loss/acc: 0.030150, 0.97\n","Sparsity fraction (ratio of non-zero weights):  0.19320350955437643\n","Train loss/acc:  (0.010983400375328281, 0.9871636481718583) Test loss/acc:  (0.09529392138123512, 0.8952999973297119)\n","Epoch:  39\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9998647, 0.9998647, 0.9998647, 0.9998647]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.010565, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.017230, 0.98\n","Iter: 110 of 550 || Estimated train loss/acc: 0.021443, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.016449, 0.98\n","Iter: 220 of 550 || Estimated train loss/acc: 0.021672, 0.97\n","Iter: 275 of 550 || Estimated train loss/acc: 0.021302, 0.97\n","Iter: 330 of 550 || Estimated train loss/acc: 0.023683, 0.95\n","Iter: 385 of 550 || Estimated train loss/acc: 0.010353, 0.99\n","Iter: 440 of 550 || Estimated train loss/acc: 0.006902, 0.99\n","Iter: 495 of 550 || Estimated train loss/acc: 0.017011, 0.98\n","Sparsity fraction (ratio of non-zero weights):  0.18742462871351312\n","Train loss/acc:  (0.011093758300624111, 0.9863272857666016) Test loss/acc:  (0.09680323034524918, 0.8963999962806701)\n","Epoch:  40\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9998715, 0.9998715, 0.9998715, 0.9998715]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.016324, 0.98\n","Iter: 55 of 550 || Estimated train loss/acc: 0.024576, 0.95\n","Iter: 110 of 550 || Estimated train loss/acc: 0.015830, 0.99\n","Iter: 165 of 550 || Estimated train loss/acc: 0.004904, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.019755, 0.97\n","Iter: 275 of 550 || Estimated train loss/acc: 0.012044, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.012886, 0.98\n","Iter: 385 of 550 || Estimated train loss/acc: 0.008503, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.017543, 0.98\n","Iter: 495 of 550 || Estimated train loss/acc: 0.021254, 0.97\n","Sparsity fraction (ratio of non-zero weights):  0.18471844299228046\n","Train loss/acc:  (0.009763047068633816, 0.9877091026306153) Test loss/acc:  (0.10156460046768188, 0.894700002670288)\n","Epoch:  41\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9998779, 0.9998779, 0.9998779, 0.9998779]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.007126, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.030984, 0.95\n","Iter: 110 of 550 || Estimated train loss/acc: 0.009495, 0.99\n","Iter: 165 of 550 || Estimated train loss/acc: 0.016617, 0.98\n","Iter: 220 of 550 || Estimated train loss/acc: 0.012608, 0.97\n","Iter: 275 of 550 || Estimated train loss/acc: 0.012455, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.022054, 0.97\n","Iter: 385 of 550 || Estimated train loss/acc: 0.018108, 0.97\n","Iter: 440 of 550 || Estimated train loss/acc: 0.027135, 0.94\n","Iter: 495 of 550 || Estimated train loss/acc: 0.010662, 0.98\n","Sparsity fraction (ratio of non-zero weights):  0.1795112170824695\n","Train loss/acc:  (0.010222867480055853, 0.9867091031508012) Test loss/acc:  (0.10058130443096161, 0.8909999918937683)\n","Epoch:  42\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.999884, 0.999884, 0.999884, 0.999884]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.011451, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.010865, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.018380, 0.99\n","Iter: 165 of 550 || Estimated train loss/acc: 0.005539, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.005499, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.021280, 0.98\n","Iter: 330 of 550 || Estimated train loss/acc: 0.005382, 0.99\n","Iter: 385 of 550 || Estimated train loss/acc: 0.018193, 0.99\n","Iter: 440 of 550 || Estimated train loss/acc: 0.019896, 0.98\n","Iter: 495 of 550 || Estimated train loss/acc: 0.007133, 0.99\n","Sparsity fraction (ratio of non-zero weights):  0.1692865523064262\n","Train loss/acc:  (0.009009638098491864, 0.9895091009140015) Test loss/acc:  (0.10947101473808289, 0.8938999962806702)\n","Epoch:  43\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9998898, 0.9998898, 0.9998898, 0.9998898]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.004472, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.004165, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.014868, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.021094, 0.98\n","Iter: 220 of 550 || Estimated train loss/acc: 0.020390, 0.98\n","Iter: 275 of 550 || Estimated train loss/acc: 0.012134, 0.98\n","Iter: 330 of 550 || Estimated train loss/acc: 0.019135, 0.99\n","Iter: 385 of 550 || Estimated train loss/acc: 0.012021, 0.98\n","Iter: 440 of 550 || Estimated train loss/acc: 0.007648, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.020876, 0.98\n","Sparsity fraction (ratio of non-zero weights):  0.1618725907616893\n","Train loss/acc:  (0.007732514224269174, 0.9906545543670654) Test loss/acc:  (0.10605525434017181, 0.896399998664856)\n","Epoch:  44\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9998953, 0.9998953, 0.9998953, 0.9998953]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.014624, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.013092, 0.99\n","Iter: 110 of 550 || Estimated train loss/acc: 0.011287, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.016068, 0.97\n","Iter: 220 of 550 || Estimated train loss/acc: 0.009902, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.009081, 0.99\n","Iter: 330 of 550 || Estimated train loss/acc: 0.016314, 0.97\n","Iter: 385 of 550 || Estimated train loss/acc: 0.020596, 0.97\n","Iter: 440 of 550 || Estimated train loss/acc: 0.027448, 0.93\n","Iter: 495 of 550 || Estimated train loss/acc: 0.018687, 0.98\n","Sparsity fraction (ratio of non-zero weights):  0.15314677489680892\n","Train loss/acc:  (0.008801879351111975, 0.9888363742828369) Test loss/acc:  (0.10956874787807465, 0.8960999989509583)\n","Epoch:  45\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999005, 0.9999005, 0.9999005, 0.9999005]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.002935, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.011454, 0.99\n","Iter: 110 of 550 || Estimated train loss/acc: 0.014441, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.010619, 0.99\n","Iter: 220 of 550 || Estimated train loss/acc: 0.005252, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.036394, 0.97\n","Iter: 330 of 550 || Estimated train loss/acc: 0.012037, 0.98\n","Iter: 385 of 550 || Estimated train loss/acc: 0.008281, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.020654, 0.97\n","Iter: 495 of 550 || Estimated train loss/acc: 0.020678, 0.97\n","Sparsity fraction (ratio of non-zero weights):  0.13580145582519565\n","Train loss/acc:  (0.005819340231405063, 0.9938363695144653) Test loss/acc:  (0.11152221888303757, 0.8941999959945679)\n","Epoch:  46\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99990547, 0.99990547, 0.99990547, 0.99990547]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.016243, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.011630, 0.98\n","Iter: 110 of 550 || Estimated train loss/acc: 0.003661, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.002834, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.011476, 0.97\n","Iter: 275 of 550 || Estimated train loss/acc: 0.018337, 0.97\n","Iter: 330 of 550 || Estimated train loss/acc: 0.003369, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.009756, 0.99\n","Iter: 440 of 550 || Estimated train loss/acc: 0.002242, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.008965, 0.99\n","Sparsity fraction (ratio of non-zero weights):  0.13043545904130316\n","Train loss/acc:  (0.005425964560021054, 0.9945636415481567) Test loss/acc:  (0.11320857867598534, 0.8958999991416932)\n","Epoch:  47\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999102, 0.9999102, 0.9999102, 0.9999102]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.005375, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.006450, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.006121, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.008914, 0.99\n","Iter: 220 of 550 || Estimated train loss/acc: 0.006404, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.005730, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.011319, 0.98\n","Iter: 385 of 550 || Estimated train loss/acc: 0.002256, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.004002, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.015513, 0.99\n","Sparsity fraction (ratio of non-zero weights):  0.12265698270713915\n","Train loss/acc:  (0.004450699912214821, 0.9958727312088013) Test loss/acc:  (0.11664706319570542, 0.8962000012397766)\n","Epoch:  48\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99991465, 0.99991465, 0.99991465, 0.99991465]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.014058, 0.98\n","Iter: 55 of 550 || Estimated train loss/acc: 0.011711, 0.98\n","Iter: 110 of 550 || Estimated train loss/acc: 0.012013, 0.98\n","Iter: 165 of 550 || Estimated train loss/acc: 0.003731, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.009504, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.005178, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.007699, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.003690, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.003496, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.023250, 0.98\n","Sparsity fraction (ratio of non-zero weights):  0.07484002238749109\n","Train loss/acc:  (0.003325443496419625, 0.9971818208694458) Test loss/acc:  (0.1163739389181137, 0.8939999938011169)\n","Epoch:  49\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99991894, 0.99991894, 0.99991894, 0.99991894]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.002134, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.004196, 0.99\n","Iter: 110 of 550 || Estimated train loss/acc: 0.021996, 0.96\n","Iter: 165 of 550 || Estimated train loss/acc: 0.013356, 0.99\n","Iter: 220 of 550 || Estimated train loss/acc: 0.003008, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.003167, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.008634, 0.99\n","Iter: 385 of 550 || Estimated train loss/acc: 0.002621, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.004096, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.005806, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.0694219663094588\n","Train loss/acc:  (0.003505550887097012, 0.9965272760391235) Test loss/acc:  (0.12346562832593917, 0.8962999939918518)\n","Epoch:  50\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.999923, 0.999923, 0.999923, 0.999923]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.005669, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.008113, 0.99\n","Iter: 110 of 550 || Estimated train loss/acc: 0.004443, 0.99\n","Iter: 165 of 550 || Estimated train loss/acc: 0.003603, 0.99\n","Iter: 220 of 550 || Estimated train loss/acc: 0.004476, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.005457, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.001883, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.006804, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.005303, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.003042, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.0660904706758573\n","Train loss/acc:  (0.002900032520886849, 0.9977454566955566) Test loss/acc:  (0.12247739881277084, 0.8961999917030334)\n","Epoch:  51\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99992687, 0.99992687, 0.99992687, 0.99992687]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.007711, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.003584, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.007711, 0.99\n","Iter: 165 of 550 || Estimated train loss/acc: 0.005775, 0.99\n","Iter: 220 of 550 || Estimated train loss/acc: 0.009640, 0.98\n","Iter: 275 of 550 || Estimated train loss/acc: 0.005602, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.007960, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.006705, 0.98\n","Iter: 440 of 550 || Estimated train loss/acc: 0.005799, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.003237, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.05660500798441971\n","Train loss/acc:  (0.002277820846489207, 0.9982363653182983) Test loss/acc:  (0.12698101967573167, 0.8978999948501587)\n","Epoch:  52\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999305, 0.9999305, 0.9999305, 0.9999305]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.009983, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.002419, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.003409, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.004931, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.011530, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.009624, 0.99\n","Iter: 330 of 550 || Estimated train loss/acc: 0.004860, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.002529, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.004176, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.006730, 0.99\n","Sparsity fraction (ratio of non-zero weights):  0.055259444772668434\n","Train loss/acc:  (0.0022163265401666816, 0.9984909105300903) Test loss/acc:  (0.13273525446653367, 0.8966000008583069)\n","Epoch:  53\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99993396, 0.99993396, 0.99993396, 0.99993396]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.003488, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.004447, 0.99\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000475, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.004465, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.005233, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.003679, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.001261, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.005555, 0.99\n","Iter: 440 of 550 || Estimated train loss/acc: 0.003088, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.005707, 0.99\n","Sparsity fraction (ratio of non-zero weights):  0.05206059063563002\n","Train loss/acc:  (0.0014843291626311839, 0.9992181825637817) Test loss/acc:  (0.13120927780866623, 0.8968999981880188)\n","Epoch:  54\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99993724, 0.99993724, 0.99993724, 0.99993724]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.002735, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.003859, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.002156, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.005547, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.008526, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.003775, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.007092, 0.99\n","Iter: 385 of 550 || Estimated train loss/acc: 0.002170, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.002591, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.003865, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.048375051909698465\n","Train loss/acc:  (0.0011952412538018754, 0.9993818187713623) Test loss/acc:  (0.1380426862835884, 0.8968999981880188)\n","Epoch:  55\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999404, 0.9999404, 0.9999404, 0.9999404]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.003105, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.002448, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.002055, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000622, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001148, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.004419, 0.99\n","Iter: 330 of 550 || Estimated train loss/acc: 0.003570, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.002469, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.003579, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.001958, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.04771643202751603\n","Train loss/acc:  (0.0009687919532668523, 0.9996545457839966) Test loss/acc:  (0.13801532804965974, 0.8973000001907349)\n","Epoch:  56\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999434, 0.9999434, 0.9999434, 0.9999434]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.002695, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.001263, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.002379, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001073, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.004940, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.004968, 0.99\n","Iter: 330 of 550 || Estimated train loss/acc: 0.001883, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.003997, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.007211, 0.99\n","Iter: 495 of 550 || Estimated train loss/acc: 0.007847, 0.99\n","Sparsity fraction (ratio of non-zero weights):  0.04523035140621927\n","Train loss/acc:  (0.0009283455833263526, 0.9996727275848388) Test loss/acc:  (0.14581306397914887, 0.8960999965667724)\n","Epoch:  57\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99994624, 0.99994624, 0.99994624, 0.99994624]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.002277, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.002350, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.007603, 0.99\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001560, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001119, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.004453, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.006340, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.003223, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.002634, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000788, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.04435182588499803\n","Train loss/acc:  (0.0006770615925250406, 0.9997636365890503) Test loss/acc:  (0.15300200045108794, 0.8953999972343445)\n","Epoch:  58\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999489, 0.9999489, 0.9999489, 0.9999489]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.006509, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.002433, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000585, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.008426, 0.99\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000392, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.003267, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.002048, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000954, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.001511, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.001575, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.04131752698805668\n","Train loss/acc:  (0.0006168790723842738, 0.9998000001907349) Test loss/acc:  (0.15458646923303604, 0.8951999926567078)\n","Epoch:  59\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999515, 0.9999515, 0.9999515, 0.9999515]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001946, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.002099, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.002302, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000987, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001172, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.002396, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.001517, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.001008, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.002518, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.003176, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.03895501239250554\n","Train loss/acc:  (0.000596601187240925, 0.9997636365890503) Test loss/acc:  (0.15633342921733856, 0.8942999958992004)\n","Epoch:  60\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999539, 0.9999539, 0.9999539, 0.9999539]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.004008, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000684, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.002341, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000605, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001013, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.004544, 0.99\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000932, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.001113, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.002483, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.004580, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.038576036688039564\n","Train loss/acc:  (0.0006553141386988996, 0.9996000003814697) Test loss/acc:  (0.1558797538280487, 0.8956999921798706)\n","Epoch:  61\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99995625, 0.99995625, 0.99995625, 0.99995625]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.002507, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000317, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.001244, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001219, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001627, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.001844, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.003083, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.004493, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.010626, 0.99\n","Iter: 495 of 550 || Estimated train loss/acc: 0.002165, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.03737907184461837\n","Train loss/acc:  (0.0003534284673316341, 0.9998909091949463) Test loss/acc:  (0.1595174103975296, 0.8981999897956848)\n","Epoch:  62\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99995846, 0.99995846, 0.99995846, 0.99995846]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001088, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.002776, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.002890, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001482, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000338, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000231, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.004334, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.004234, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.002295, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.001832, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.037052953277880545\n","Train loss/acc:  (0.0002834354528683682, 1.0) Test loss/acc:  (0.1627652907371521, 0.8966999959945678)\n","Epoch:  63\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99996054, 0.99996054, 0.99996054, 0.99996054]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000165, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.001228, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.001644, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000288, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.003554, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000698, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.007330, 0.99\n","Iter: 385 of 550 || Estimated train loss/acc: 0.001019, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000374, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.001536, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.03646334686609033\n","Train loss/acc:  (0.00022532214803504757, 1.0) Test loss/acc:  (0.1674499899148941, 0.8961999917030334)\n","Epoch:  64\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999625, 0.9999625, 0.9999625, 0.9999625]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001587, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.004143, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000602, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000545, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001169, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000299, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000040, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000249, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.003329, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000141, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.034169945471379956\n","Train loss/acc:  (0.00018809954877228434, 0.9999818181991578) Test loss/acc:  (0.16867507010698318, 0.8960999917984008)\n","Epoch:  65\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99996436, 0.99996436, 0.99996436, 0.99996436]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.003164, 0.99\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000232, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000298, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000561, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001062, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.002618, 0.99\n","Iter: 330 of 550 || Estimated train loss/acc: 0.003166, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000440, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.001107, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000753, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.033822983240896505\n","Train loss/acc:  (0.00022863153456042213, 0.9999454545974732) Test loss/acc:  (0.17144036829471587, 0.8966000008583069)\n","Epoch:  66\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99996614, 0.99996614, 0.99996614, 0.99996614]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000069, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.002232, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000874, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001281, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000969, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.002056, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000978, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000363, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.001627, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000736, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.033448495406615\n","Train loss/acc:  (0.00016865861993871725, 0.9999636363983154) Test loss/acc:  (0.17621150344610215, 0.8967999958992005)\n","Epoch:  67\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999678, 0.9999678, 0.9999678, 0.9999678]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.002368, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000121, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000062, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000743, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000461, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.001926, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000362, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000462, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.001087, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.002056, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.03313294826742281\n","Train loss/acc:  (0.00014924378617541318, 1.0) Test loss/acc:  (0.17322312146425248, 0.8969999933242798)\n","Epoch:  68\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999694, 0.9999694, 0.9999694, 0.9999694]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001435, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.002298, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000378, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001451, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001182, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.003193, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.005522, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.002512, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.001484, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.001435, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.03298843884748302\n","Train loss/acc:  (0.00012270577276968776, 1.0) Test loss/acc:  (0.1843077600002289, 0.8972999978065491)\n","Epoch:  69\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.999971, 0.999971, 0.999971, 0.999971]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000756, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.003029, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.001347, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000926, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000148, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000587, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000871, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.003333, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000469, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000509, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.03277302107862868\n","Train loss/acc:  (0.00010244453776858171, 1.0) Test loss/acc:  (0.18537163078784943, 0.8964999961853027)\n","Epoch:  70\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999724, 0.9999724, 0.9999724, 0.9999724]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001718, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.002667, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000001, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001425, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000064, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000370, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000188, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.001319, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000212, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000621, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.032582635652358805\n","Train loss/acc:  (7.152486880153736e-05, 0.9999818181991578) Test loss/acc:  (0.18178022295236587, 0.8965999960899353)\n","Epoch:  71\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999738, 0.9999738, 0.9999738, 0.9999738]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000053, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.001116, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000185, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000115, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000277, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000273, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000048, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.001713, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000018, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000239, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.03228992678588311\n","Train loss/acc:  (5.614807647554701e-05, 1.0) Test loss/acc:  (0.1870037531852722, 0.8966999936103821)\n","Epoch:  72\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999751, 0.9999751, 0.9999751, 0.9999751]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000617, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000903, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000424, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000393, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001895, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.001847, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000024, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000856, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000100, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000270, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.032008686920989946\n","Train loss/acc:  (5.208143360835022e-05, 1.0) Test loss/acc:  (0.18911769479513169, 0.8954999923706055)\n","Epoch:  73\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99997634, 0.99997634, 0.99997634, 0.99997634]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000338, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000026, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000035, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000403, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001577, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000519, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.001078, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.002385, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.001452, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000135, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.031482110152679335\n","Train loss/acc:  (7.05922722298944e-05, 1.0) Test loss/acc:  (0.1836428999900818, 0.8927999901771545)\n","Epoch:  74\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999775, 0.9999775, 0.9999775, 0.9999775]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001602, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.001525, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000082, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000116, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000043, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000221, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000319, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000012, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000324, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.030874153338357087\n","Train loss/acc:  (5.565729700965573e-05, 1.0) Test loss/acc:  (0.18925455421209336, 0.8937999939918518)\n","Epoch:  75\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99997866, 0.99997866, 0.99997866, 0.99997866]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000650, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000198, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000401, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.005657, 0.99\n","Iter: 220 of 550 || Estimated train loss/acc: 0.002101, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.001836, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000008, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.001170, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.002007, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.030796762510287196\n","Train loss/acc:  (4.5586409122211146e-05, 1.0) Test loss/acc:  (0.20446333706378936, 0.8953999972343445)\n","Epoch:  76\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99997973, 0.99997973, 0.99997973, 0.99997973]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001076, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000165, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000300, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000969, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001761, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000244, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.004848, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000112, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000953, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.001007, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.03070899971556876\n","Train loss/acc:  (5.3125326986386376e-05, 1.0) Test loss/acc:  (0.1968314206600189, 0.8937999963760376)\n","Epoch:  77\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99998075, 0.99998075, 0.99998075, 0.99998075]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.002110, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000895, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000471, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001490, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001935, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000081, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.003238, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000608, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.003171, 0.99\n","Sparsity fraction (ratio of non-zero weights):  0.030656242308289155\n","Train loss/acc:  (4.004212990594169e-05, 1.0) Test loss/acc:  (0.1989571964740753, 0.8951999950408935)\n","Epoch:  78\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999817, 0.9999817, 0.9999817, 0.9999817]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000415, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.001860, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.001192, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000280, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000078, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000066, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000680, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.001861, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000529, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.002041, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.03052370054217461\n","Train loss/acc:  (3.111591315978046e-05, 1.0) Test loss/acc:  (0.20299135833978654, 0.8946999979019165)\n","Epoch:  79\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999826, 0.9999826, 0.9999826, 0.9999826]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000732, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.001694, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.001213, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001873, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000331, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.001595, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.002594, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000796, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000244, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000035, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.03042496739811637\n","Train loss/acc:  (2.4829699521385413e-05, 1.0) Test loss/acc:  (0.20887499034404755, 0.8971999979019165)\n","Epoch:  80\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999835, 0.9999835, 0.9999835, 0.9999835]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000445, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000403, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000071, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000071, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000524, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000526, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000092, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000139, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.001456, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.001690, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.030192495722561063\n","Train loss/acc:  (1.7766811786526755e-05, 1.0) Test loss/acc:  (0.20461578756570817, 0.8970000004768371)\n","Epoch:  81\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999843, 0.9999843, 0.9999843, 0.9999843]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001884, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.002324, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000077, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000233, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.002378, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000075, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000241, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000098, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.030095457996128065\n","Train loss/acc:  (2.4241639081189682e-05, 1.0) Test loss/acc:  (0.2153391569852829, 0.8970000004768371)\n","Epoch:  82\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999851, 0.9999851, 0.9999851, 0.9999851]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000023, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000824, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000112, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001727, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000150, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000047, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.001209, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.005983, 0.99\n","Sparsity fraction (ratio of non-zero weights):  0.029907964752865952\n","Train loss/acc:  (1.651903887521954e-05, 1.0) Test loss/acc:  (0.21635882973670958, 0.8949999976158142)\n","Epoch:  83\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999858, 0.9999858, 0.9999858, 0.9999858]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000087, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000208, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000196, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000182, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000281, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.001116, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000020, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000674, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000207, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029873458017669843\n","Train loss/acc:  (1.1560699595169023e-05, 1.0) Test loss/acc:  (0.21247959971427918, 0.8967999982833862)\n","Epoch:  84\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999865, 0.9999865, 0.9999865, 0.9999865]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000005, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000531, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000719, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001262, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000047, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000146, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000038, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.001089, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000006, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.002747, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029776719482582478\n","Train loss/acc:  (1.3856562866261852e-05, 1.0) Test loss/acc:  (0.21048148036003111, 0.8956999945640564)\n","Epoch:  85\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999872, 0.9999872, 0.9999872, 0.9999872]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001099, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000230, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000536, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000034, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000437, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000039, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.001633, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000002, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000373, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.02964088661166599\n","Train loss/acc:  (9.343358229749945e-06, 1.0) Test loss/acc:  (0.22228924036026002, 0.8972999930381775)\n","Epoch:  86\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99998784, 0.99998784, 0.99998784, 0.99998784]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000001, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000109, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000002, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000842, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000033, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000091, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000009, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000368, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000127, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000386, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.02961864672164075\n","Train loss/acc:  (8.942734872509982e-06, 1.0) Test loss/acc:  (0.2324556303024292, 0.8957999992370606)\n","Epoch:  87\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99998844, 0.99998844, 0.99998844, 0.99998844]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001580, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000155, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000074, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000003, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.003383, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000611, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000566, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000111, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000276, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.001996, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029605781493778616\n","Train loss/acc:  (6.271000223535853e-06, 1.0) Test loss/acc:  (0.2272496610879898, 0.8966999983787537)\n","Epoch:  88\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99998903, 0.99998903, 0.99998903, 0.99998903]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000258, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000094, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000162, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000237, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000010, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000108, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000839, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000008, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.0295760618201126\n","Train loss/acc:  (1.2784430775475722e-05, 1.0) Test loss/acc:  (0.22058062076568605, 0.8959999942779541)\n","Epoch:  89\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99998957, 0.99998957, 0.99998957, 0.99998957]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001865, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000367, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000485, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000583, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000055, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000756, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000100, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.001038, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000481, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029534474223069887\n","Train loss/acc:  (1.0029054255275711e-05, 1.0) Test loss/acc:  (0.22761006593704225, 0.8959999942779541)\n","Epoch:  90\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999901, 0.9999901, 0.9999901, 0.9999901]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000318, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000003, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000620, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000414, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000049, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000083, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000037, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000085, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000067, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.003502, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029503956705815522\n","Train loss/acc:  (2.349891808263878e-05, 1.0) Test loss/acc:  (0.22985388338565826, 0.8940000009536743)\n","Epoch:  91\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999906, 0.9999906, 0.9999906, 0.9999906]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000313, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000029, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000693, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000156, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000007, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000035, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000009, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000018, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000213, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.002572, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029476929754260184\n","Train loss/acc:  (4.814878106797432e-06, 1.0) Test loss/acc:  (0.2286086255311966, 0.894199993610382)\n","Epoch:  92\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99999106, 0.99999106, 0.99999106, 0.99999106]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000008, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000007, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000315, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000081, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000005, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000065, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000354, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029465859674471837\n","Train loss/acc:  (7.035541484580693e-06, 1.0) Test loss/acc:  (0.23948489427566527, 0.8951000022888184)\n","Epoch:  93\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99999154, 0.99999154, 0.99999154, 0.99999154]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000011, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000272, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000147, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.002494, 0.99\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000150, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000009, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000810, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000114, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000065, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.02944501601072621\n","Train loss/acc:  (5.012689859420696e-06, 1.0) Test loss/acc:  (0.22665029048919677, 0.8962999987602234)\n","Epoch:  94\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99999195, 0.99999195, 0.99999195, 0.99999195]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000224, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000027, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000113, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001593, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.005571, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000474, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000904, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000002, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000038, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029393255907932042\n","Train loss/acc:  (4.833225861770949e-06, 1.0) Test loss/acc:  (0.23401294887065888, 0.8959999990463257)\n","Epoch:  95\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999924, 0.9999924, 0.9999924, 0.9999924]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000175, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000141, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000148, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000105, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000756, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000768, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029372412244186415\n","Train loss/acc:  (3.4949365749396705e-06, 1.0) Test loss/acc:  (0.23534932971000672, 0.8958999967575073)\n","Epoch:  96\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999927, 0.9999927, 0.9999927, 0.9999927]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000510, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000105, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000275, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000472, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000185, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000430, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.001732, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000133, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000080, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029339700657064087\n","Train loss/acc:  (7.010878255253272e-06, 1.0) Test loss/acc:  (0.23843773782253266, 0.8969999980926514)\n","Epoch:  97\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999931, 0.9999931, 0.9999931, 0.9999931]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000709, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000875, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000025, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000140, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000185, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000999, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000453, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029302202008411667\n","Train loss/acc:  (4.0803489539181275e-06, 1.0) Test loss/acc:  (0.2425454503297806, 0.8961999988555909)\n","Epoch:  98\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99999344, 0.99999344, 0.99999344, 0.99999344]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.001774, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000236, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.001878, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.001435, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000032, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000486, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000042, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.029237875869100993\n","Train loss/acc:  (4.1296747186684e-06, 1.0) Test loss/acc:  (0.23787909507751465, 0.8944999980926513)\n","Epoch:  99\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9999938, 0.9999938, 0.9999938, 0.9999938]\n","rho:\n","[0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.000030, 1.00\n","Iter: 55 of 550 || Estimated train loss/acc: 0.000003, 1.00\n","Iter: 110 of 550 || Estimated train loss/acc: 0.000110, 1.00\n","Iter: 165 of 550 || Estimated train loss/acc: 0.000318, 1.00\n","Iter: 220 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 275 of 550 || Estimated train loss/acc: 0.000540, 1.00\n","Iter: 330 of 550 || Estimated train loss/acc: 0.000024, 1.00\n","Iter: 385 of 550 || Estimated train loss/acc: 0.000024, 1.00\n","Iter: 440 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Iter: 495 of 550 || Estimated train loss/acc: 0.000000, 1.00\n","Sparsity fraction (ratio of non-zero weights):  0.02913684892472625\n","Train loss/acc:  (4.7140510340297355e-06, 1.0) Test loss/acc:  (0.2367365700006485, 0.8935999917984009)\n"]}],"source":["losses_and_accs_train = []\n","losses_and_accs_valid = []\n","losses_and_accs_test = []\n","sparsity_fracs = []\n","\n","n_epochs = 100\n","\n","for t in range(n_epochs):\n","    print('Epoch: ', t)\n","    opt.train_epoch(batch_size=100, ema_decay=0.95, n_output=10, verbose=True)\n","    \n","    losses_and_accs_train.append(\n","        opt.loss_and_accuracy((x_train, y_train), max_batch=400, inference=True))\n","    losses_and_accs_test.append(\n","        opt.loss_and_accuracy((x_test, y_test), max_batch=400, inference=True))\n","    losses_and_accs_valid.append(\n","        opt.loss_and_accuracy((x_validate, y_validate), max_batch=400, inference=True))\n","    sparsity_fracs.append(utils.get_sparsity_frac(nn, opt))\n","\n","    print('Train loss/acc: ', losses_and_accs_train[-1],\n","          'Test loss/acc: ', losses_and_accs_test[-1])\n","\n","losses_and_accs_train = np.asarray(losses_and_accs_train)\n","losses_and_accs_valid = np.asarray(losses_and_accs_valid)\n","losses_and_accs_test = np.asarray(losses_and_accs_test)\n","sparsity_fracs = np.asarray(sparsity_fracs)"]},{"cell_type":"markdown","source":["Results"],"metadata":{"id":"Q7zDdCnyqRYm"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ORNVLbfKlQI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639488574038,"user_tz":-480,"elapsed":1479,"user":{"displayName":"Beren Chang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597837265257864826"}},"outputId":"9133960a-9815-4c4f-c5c7-c5f9f0ff0bcd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train:  (4.714051142813829e-06, 1.0)\n","Valid:  (0.21938569843769073, 0.8999999761581421)\n","Test:  (0.23673656582832336, 0.8935999870300293)\n"]}],"source":["print('Train: ', opt.loss_and_accuracy((x_train, y_train), inference=True))\n","print('Valid: ', opt.loss_and_accuracy((x_validate, y_validate), inference=True))\n","print('Test: ', opt.loss_and_accuracy((x_test, y_test), inference=True))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Crpjkj73KnCL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639488581220,"user_tz":-480,"elapsed":831,"user":{"displayName":"Beren Chang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597837265257864826"}},"outputId":"768e9c4a-1aa5-4f02-f649-e015e3302a7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Best epoch:  97\n","Train acc:  1.0\n","Valid acc:  0.900599992275238\n","Test acc:  0.8969999980926514\n"]}],"source":["best_epoch = np.argmax(losses_and_accs_valid[:,5]) + 1\n","print('Best epoch: ', best_epoch)\n","print('Train acc: ', losses_and_accs_train[best_epoch-1, 1])\n","print('Valid acc: ', losses_and_accs_valid[best_epoch-1, 1])\n","print('Test acc: ', losses_and_accs_test[best_epoch-1, 1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6nm8-y6WKpMT","colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"status":"ok","timestamp":1639488654741,"user_tz":-480,"elapsed":2034,"user":{"displayName":"Beren Chang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10597837265257864826"}},"outputId":"9d0e41e4-3ce6-43ee-f8ce-e5392119b221"},"outputs":[{"output_type":"stream","name":"stdout","text":["Final results:  [4.71405103e-06 1.00000000e+00 2.19385690e-01 8.99999993e-01\n"," 2.36736570e-01 8.93599992e-01]\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 720x216 with 3 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["losses_and_accs = np.concatenate(\n","    [np.asarray(losses_and_accs_train),\n","     np.asarray(losses_and_accs_valid),\n","     np.asarray(losses_and_accs_test)], axis=1)\n","\n","# Plot\n","fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,3))\n","ax1.semilogy(losses_and_accs[:,0], '-o', label='Train loss')\n","ax1.semilogy(losses_and_accs[:,2], '-o', label='Valid loss')\n","ax1.semilogy(losses_and_accs[:,4], '-o', label='Test loss')\n","\n","ax2.plot(losses_and_accs[:,1], '-o', label='Train acc')\n","ax2.plot(losses_and_accs[:,3], '-o', label='Valid acc')\n","ax2.plot(losses_and_accs[:,5], '-o', label='Test acc')\n","\n","ax3.plot(sparsity_fracs, '-o', label='Sparsity')\n","\n","for ax in [ax1,ax2,ax3]:\n","    ax.legend()\n","\n","ax2.set_ylim(0.8,1)\n","    \n","print('Final results: ', losses_and_accs[-1])"]},{"cell_type":"markdown","metadata":{"id":"L7OCip10UVCv"},"source":["save variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KgkFPVJUVZ1n"},"outputs":[],"source":["# Train loss\n","# Train acc\n","# Valid loss\n","# Valid acc\n","# Test loss\n","# Test acc\n","# Sparsity\n","df = pd.DataFrame({\"Train loss\": losses_and_accs[:,0],\n","           \"Train acc\": losses_and_accs[:,1],\n","           \"Valid loss\": losses_and_accs[:,2],\n","           \"Valid acc\": losses_and_accs[:,3],\n","           \"Test loss\": losses_and_accs[:,4],\n","           \"Test acc\": losses_and_accs[:,5],\n","           \"Sparsity\": sparsity_fracs})\n","df.to_csv(\"ternary_3hidden_softplus_l2.csv\")"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"456project_training.ipynb","provenance":[{"file_id":"1j_bUKD2ltFRGMtYTBxJ1zMJuFMBCBkT-","timestamp":1639476683685},{"file_id":"10wpDyqQfWAXm-hyuwT3ang0M3fxewJjf","timestamp":1639469663960},{"file_id":"13iiXxCxa25D9KSMIi1bfNONOiUqUIk7m","timestamp":1639037968841}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}