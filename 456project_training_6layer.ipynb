{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"456project_fashion_mnist_ternary_6layer.ipynb","provenance":[{"file_id":"13iiXxCxa25D9KSMIi1bfNONOiUqUIk7m","timestamp":1639037968841}],"collapsed_sections":[],"mount_file_id":"10wpDyqQfWAXm-hyuwT3ang0M3fxewJjf","authorship_tag":"ABX9TyOKw9QNui1B7LOAoZ5lSdQq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Data preparation"],"metadata":{"id":"sP4aQJGXUHru"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z_irnw6M-tXS","executionInfo":{"status":"ok","timestamp":1639444609192,"user_tz":-480,"elapsed":7420,"user":{"displayName":"Haocheng Chang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13307480833404158561"}},"outputId":"c9fa32a0-61e5-4128-a3c3-522c9c3b9f85"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__) # 1.4.1\n","import network, train, utils\n","from layers import SigmoidLayer, ReluLayer, TanhLayer, SoftPlusLayer, TernaryFullyConnectedLayer, BatchNormLayer\n","import os\n","\n","import distutils\n","''' compatible with 1.15\n","if distutils.version.LooseVersion(tf.__version__) <= '2.0':\n","    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/fashion_mnist.ipynb')\n","'''\n","\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n","\n","# add empty color dimension\n","# x_train = np.expand_dims(x_train, -1)\n","# x_test = np.expand_dims(x_test, -1)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n","1.15.2\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/network.py:15: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\n","\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","32768/29515 [=================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","8192/5148 [===============================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","metadata":{"id":"-h-pPQYLAjdw"},"source":["images = np.concatenate([x_train, x_test], axis=0)\n","labels = np.concatenate([y_train, y_test], axis=0)\n","\n","n_train, n_valid, n_test = 55000, 5000, 10000\n","\n","images = images.reshape(70000, 784)\n","y_labels = np.zeros((70000,10), dtype=int)\n","\n","for i in range(70000):\n","  y_labels[i][labels[i]] = 1\n","\n","x_train = images[:n_train]\n","y_train = y_labels[:n_train]\n","x_validate = images[n_train:n_train+n_valid]\n","y_validate = y_labels[n_train:n_train+n_valid]\n","x_test = images[-n_test:]\n","y_test = y_labels[-n_test:]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-QK1BmsjATlZ","executionInfo":{"status":"ok","timestamp":1639407186439,"user_tz":-480,"elapsed":3271,"user":{"displayName":"Haocheng Chang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13307480833404158561"}},"outputId":"2bc7ac2f-9c44-40d0-c885-c4c79d21d7c2"},"source":["nn = network.NeuralNetwork(in_size=[None, 784], n_out_classes=10, loss_func=utils.smooth_hinge_loss)\n","\n","nn.reset_graph()\n","\n","# Hidden FC-1\n","nn.add_layer(TernaryFullyConnectedLayer(out_dim=2048))\n","nn.add_layer(BatchNormLayer(axes=[0]))\n","nn.add_layer(ReluLayer())\n","\n","# Hidden FC-2\n","nn.add_layer(TernaryFullyConnectedLayer(out_dim=2048))\n","nn.add_layer(BatchNormLayer(axes=[0]))\n","nn.add_layer(SoftplusLayer())\n","\n","# Hidden FC-3\n","nn.add_layer(TernaryFullyConnectedLayer(out_dim=2048))\n","nn.add_layer(BatchNormLayer(axes=[0]))\n","nn.add_layer(ReluLayer())\n","\n","# Hidden FC-4\n","nn.add_layer(TernaryFullyConnectedLayer(out_dim=2048))\n","nn.add_layer(BatchNormLayer(axes=[0]))\n","nn.add_layer(SoftplusLayer())\n","\n","# Hidden FC-5\n","nn.add_layer(TernaryFullyConnectedLayer(out_dim=2048))\n","nn.add_layer(BatchNormLayer(axes=[0]))\n","nn.add_layer(ReluLayer())\n","\n","# Hidden FC-6\n","nn.add_layer(TernaryFullyConnectedLayer(out_dim=2048))\n","nn.add_layer(BatchNormLayer(axes=[0]))\n","nn.add_layer(SoftplusLayer())\n","\n","# Output SVM layer (linear part)\n","nn.add_layer(TernaryFullyConnectedLayer(out_dim=10))\n","nn.add_layer(BatchNormLayer(axes=[0]))\n","\n","nn.finalize()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/network.py:35: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/network.py:36: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/layers.py:273: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/layers.py:276: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.flatten instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/layers.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/layers.py:313: The name tf.assign_sub is deprecated. Please use tf.compat.v1.assign_sub instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/layers.py:319: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/layers.py:580: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/network.py:89: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/network.py:89: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/network.py:90: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/network.py:91: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpKRBFWaAbe4","executionInfo":{"status":"ok","timestamp":1639407194662,"user_tz":-480,"elapsed":2912,"user":{"displayName":"Haocheng Chang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13307480833404158561"}},"outputId":"6a00ceb3-9cda-41a5-d2ee-91e61afedf4d"},"source":["data_train = (x_train, y_train)\n","opt = train.Trainer(nn, data_train)\n","\n","opt.set_rho(0.5)\n","opt.set_ema_rates(0.999)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/train.py:29: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TEwpzo09AeCl","outputId":"e5fc1b6a-8c80-4df7-dc3e-f2deca9ee289"},"source":["losses_and_accs_train = []\n","losses_and_accs_valid = []\n","losses_and_accs_test = []\n","sparsity_fracs = []\n","\n","n_epochs = 100\n","\n","for t in range(n_epochs):\n","    print('Epoch: ', t)\n","    opt.train_epoch(batch_size=100, ema_decay=0.95, n_output=10, verbose=True)\n","    \n","    losses_and_accs_train.append(\n","        opt.loss_and_accuracy((x_train, y_train), max_batch=400, inference=True))\n","    losses_and_accs_test.append(\n","        opt.loss_and_accuracy((x_test, y_test), max_batch=400, inference=True))\n","    losses_and_accs_valid.append(\n","        opt.loss_and_accuracy((x_validate, y_validate), max_batch=400, inference=True))\n","    sparsity_fracs.append(utils.get_sparsity_frac(nn, opt))\n","\n","    print('Train loss/acc: ', losses_and_accs_train[-1],\n","          'Test loss/acc: ', losses_and_accs_test[-1])\n","\n","losses_and_accs_train = np.asarray(losses_and_accs_train)\n","losses_and_accs_valid = np.asarray(losses_and_accs_valid)\n","losses_and_accs_test = np.asarray(losses_and_accs_test)\n","sparsity_fracs = np.asarray(sparsity_fracs)"],"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch:  0\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.999, 0.999, 0.999, 0.999, 0.999, 0.999, 0.999]\n","rho:\n","[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 1.814184, 0.64\n","Iter: 55 of 550 || Estimated train loss/acc: 1.355227, 0.62\n","Iter: 110 of 550 || Estimated train loss/acc: 1.154036, 0.68\n","Iter: 165 of 550 || Estimated train loss/acc: 1.040917, 0.69\n","Iter: 220 of 550 || Estimated train loss/acc: 1.006028, 0.69\n","Iter: 275 of 550 || Estimated train loss/acc: 0.912739, 0.67\n","Iter: 330 of 550 || Estimated train loss/acc: 0.945748, 0.66\n","Iter: 385 of 550 || Estimated train loss/acc: 0.671390, 0.82\n","Iter: 440 of 550 || Estimated train loss/acc: 0.699131, 0.78\n","Iter: 495 of 550 || Estimated train loss/acc: 0.615671, 0.73\n","WARNING:tensorflow:From /content/drive/MyDrive/discrete-MSA-master/utils.py:48: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","Sparsity fraction (ratio of non-zero weights):  0.8456823085683691\n","Train loss/acc:  (0.5471805943142284, 0.811181819005446) Test loss/acc:  (0.5650631761550904, 0.7947000050544739)\n","Epoch:  1\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99905, 0.99905, 0.99905, 0.99905, 0.99905, 0.99905, 0.99905]\n","rho:\n","[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.608795, 0.79\n","Iter: 55 of 550 || Estimated train loss/acc: 0.458339, 0.89\n","Iter: 110 of 550 || Estimated train loss/acc: 0.614044, 0.75\n","Iter: 165 of 550 || Estimated train loss/acc: 0.460272, 0.75\n","Iter: 220 of 550 || Estimated train loss/acc: 0.461171, 0.75\n","Iter: 275 of 550 || Estimated train loss/acc: 0.346375, 0.79\n","Iter: 330 of 550 || Estimated train loss/acc: 0.350883, 0.82\n","Iter: 385 of 550 || Estimated train loss/acc: 0.321347, 0.83\n","Iter: 440 of 550 || Estimated train loss/acc: 0.316330, 0.80\n","Iter: 495 of 550 || Estimated train loss/acc: 0.233643, 0.83\n","Sparsity fraction (ratio of non-zero weights):  0.8326193600382774\n","Train loss/acc:  (0.22665519367564807, 0.8470727304978805) Test loss/acc:  (0.24782912373542787, 0.8303999948501587)\n","Epoch:  2\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9990975, 0.9990975, 0.9990975, 0.9990975, 0.9990975, 0.9990975, 0.9990975]\n","rho:\n","[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.252159, 0.86\n","Iter: 55 of 550 || Estimated train loss/acc: 0.202783, 0.85\n","Iter: 110 of 550 || Estimated train loss/acc: 0.250795, 0.80\n","Iter: 165 of 550 || Estimated train loss/acc: 0.208071, 0.87\n","Iter: 220 of 550 || Estimated train loss/acc: 0.183887, 0.87\n","Iter: 275 of 550 || Estimated train loss/acc: 0.155879, 0.88\n","Iter: 330 of 550 || Estimated train loss/acc: 0.154412, 0.87\n","Iter: 385 of 550 || Estimated train loss/acc: 0.159605, 0.85\n","Iter: 440 of 550 || Estimated train loss/acc: 0.105210, 0.91\n","Iter: 495 of 550 || Estimated train loss/acc: 0.124669, 0.91\n","Sparsity fraction (ratio of non-zero weights):  0.8122379899981558\n","Train loss/acc:  (0.1324404218521985, 0.8843454508347944) Test loss/acc:  (0.14990858793258666, 0.8635000038146973)\n","Epoch:  3\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.99914265, 0.99914265, 0.99914265, 0.99914265, 0.99914265, 0.99914265, 0.99914265]\n","rho:\n","[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.111979, 0.89\n","Iter: 55 of 550 || Estimated train loss/acc: 0.122538, 0.87\n","Iter: 110 of 550 || Estimated train loss/acc: 0.128336, 0.86\n","Iter: 165 of 550 || Estimated train loss/acc: 0.117697, 0.87\n","Iter: 220 of 550 || Estimated train loss/acc: 0.077391, 0.91\n","Iter: 275 of 550 || Estimated train loss/acc: 0.155276, 0.81\n","Iter: 330 of 550 || Estimated train loss/acc: 0.095302, 0.88\n","Iter: 385 of 550 || Estimated train loss/acc: 0.077558, 0.93\n","Iter: 440 of 550 || Estimated train loss/acc: 0.091112, 0.87\n","Iter: 495 of 550 || Estimated train loss/acc: 0.083301, 0.91\n","Sparsity fraction (ratio of non-zero weights):  0.7857067394069231\n","Train loss/acc:  (0.08920597669753161, 0.8970363593101501) Test loss/acc:  (0.10814270287752152, 0.8702999973297119)\n","Epoch:  4\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9991855, 0.9991855, 0.9991855, 0.9991855, 0.9991855, 0.9991855, 0.9991855]\n","rho:\n","[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.065555, 0.92\n","Iter: 55 of 550 || Estimated train loss/acc: 0.071146, 0.90\n","Iter: 110 of 550 || Estimated train loss/acc: 0.046525, 0.94\n","Iter: 165 of 550 || Estimated train loss/acc: 0.086365, 0.89\n","Iter: 220 of 550 || Estimated train loss/acc: 0.060848, 0.93\n","Iter: 275 of 550 || Estimated train loss/acc: 0.082484, 0.88\n","Iter: 330 of 550 || Estimated train loss/acc: 0.069101, 0.90\n","Iter: 385 of 550 || Estimated train loss/acc: 0.095864, 0.89\n","Iter: 440 of 550 || Estimated train loss/acc: 0.157453, 0.86\n","Iter: 495 of 550 || Estimated train loss/acc: 0.069116, 0.88\n","Sparsity fraction (ratio of non-zero weights):  0.7451576829656212\n","Train loss/acc:  (0.07094818166711114, 0.8988181755759499) Test loss/acc:  (0.09335082590579986, 0.8721000003814697)\n","Epoch:  5\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9992262, 0.9992262, 0.9992262, 0.9992262, 0.9992262, 0.9992262, 0.9992262]\n","rho:\n","[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.054696, 0.90\n","Iter: 55 of 550 || Estimated train loss/acc: 0.081341, 0.87\n","Iter: 110 of 550 || Estimated train loss/acc: 0.102658, 0.85\n","Iter: 165 of 550 || Estimated train loss/acc: 0.070249, 0.91\n","Iter: 220 of 550 || Estimated train loss/acc: 0.048781, 0.91\n","Iter: 275 of 550 || Estimated train loss/acc: 0.132666, 0.85\n","Iter: 330 of 550 || Estimated train loss/acc: 0.074986, 0.85\n","Iter: 385 of 550 || Estimated train loss/acc: 0.078173, 0.87\n","Iter: 440 of 550 || Estimated train loss/acc: 0.045872, 0.92\n","Iter: 495 of 550 || Estimated train loss/acc: 0.060386, 0.88\n","Sparsity fraction (ratio of non-zero weights):  0.7034462299646171\n","Train loss/acc:  (0.05613550604744391, 0.9060181836648421) Test loss/acc:  (0.07630743756890297, 0.8780999994277954)\n","Epoch:  6\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9992649, 0.9992649, 0.9992649, 0.9992649, 0.9992649, 0.9992649, 0.9992649]\n","rho:\n","[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.045634, 0.93\n","Iter: 55 of 550 || Estimated train loss/acc: 0.065842, 0.89\n","Iter: 110 of 550 || Estimated train loss/acc: 0.072117, 0.86\n","Iter: 165 of 550 || Estimated train loss/acc: 0.061073, 0.90\n","Iter: 220 of 550 || Estimated train loss/acc: 0.039147, 0.96\n","Iter: 275 of 550 || Estimated train loss/acc: 0.054318, 0.91\n","Iter: 330 of 550 || Estimated train loss/acc: 0.054952, 0.93\n","Iter: 385 of 550 || Estimated train loss/acc: 0.057551, 0.93\n","Iter: 440 of 550 || Estimated train loss/acc: 0.061962, 0.90\n","Iter: 495 of 550 || Estimated train loss/acc: 0.071492, 0.88\n","Sparsity fraction (ratio of non-zero weights):  0.5788734867317225\n","Train loss/acc:  (0.057213541282848876, 0.9090727316249501) Test loss/acc:  (0.07832229942083359, 0.8764999985694886)\n","Epoch:  7\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9993017, 0.9993017, 0.9993017, 0.9993017, 0.9993017, 0.9993017, 0.9993017]\n","rho:\n","[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.040460, 0.96\n","Iter: 55 of 550 || Estimated train loss/acc: 0.035297, 0.97\n","Iter: 110 of 550 || Estimated train loss/acc: 0.048523, 0.93\n","Iter: 165 of 550 || Estimated train loss/acc: 0.063037, 0.90\n","Iter: 220 of 550 || Estimated train loss/acc: 0.058234, 0.92\n","Iter: 275 of 550 || Estimated train loss/acc: 0.054485, 0.91\n","Iter: 330 of 550 || Estimated train loss/acc: 0.058164, 0.91\n","Iter: 385 of 550 || Estimated train loss/acc: 0.059925, 0.91\n","Iter: 440 of 550 || Estimated train loss/acc: 0.046649, 0.95\n","Iter: 495 of 550 || Estimated train loss/acc: 0.090792, 0.87\n","Sparsity fraction (ratio of non-zero weights):  0.46298317743062267\n","Train loss/acc:  (0.05290386668660424, 0.9151636450940912) Test loss/acc:  (0.07320980980992317, 0.8787999963760376)\n","Epoch:  8\n","========= Begin epoch =========\n","batch_size = 100\n","EMA rates:\n","[0.9993366, 0.9993366, 0.9993366, 0.9993366, 0.9993366, 0.9993366, 0.9993366]\n","rho:\n","[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n","Iter: 0 of 550 || Estimated train loss/acc: 0.059950, 0.91\n","Iter: 55 of 550 || Estimated train loss/acc: 0.039625, 0.93\n","Iter: 110 of 550 || Estimated train loss/acc: 0.045537, 0.93\n","Iter: 165 of 550 || Estimated train loss/acc: 0.047193, 0.92\n","Iter: 220 of 550 || Estimated train loss/acc: 0.033209, 0.96\n","Iter: 275 of 550 || Estimated train loss/acc: 0.070625, 0.94\n","Iter: 330 of 550 || Estimated train loss/acc: 0.049076, 0.92\n"]}]},{"cell_type":"code","metadata":{"id":"6ORNVLbfKlQI"},"source":["print('Train: ', opt.loss_and_accuracy((x_train, y_train), inference=True))\n","print('Valid: ', opt.loss_and_accuracy((x_validate, y_validate), inference=True))\n","print('Test: ', opt.loss_and_accuracy((x_test, y_test), inference=True))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Crpjkj73KnCL"},"source":["best_epoch = np.argmax(losses_and_accs_valid[:,1]) + 1\n","print('Best epoch: ', best_epoch)\n","print('Train acc: ', losses_and_accs_train[best_epoch-1, 1])\n","print('Valid acc: ', losses_and_accs_valid[best_epoch-1, 1])\n","print('Test acc: ', losses_and_accs_test[best_epoch-1, 1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6nm8-y6WKpMT"},"source":["losses_and_accs = np.concatenate(\n","    [np.asarray(losses_and_accs_train),\n","     np.asarray(losses_and_accs_valid),\n","     np.asarray(losses_and_accs_test)], axis=1)\n","\n","# Plot\n","fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10,3))\n","ax1.semilogy(losses_and_accs[:,0], '-o', label='Train loss')\n","ax1.semilogy(losses_and_accs[:,2], '-o', label='Valid loss')\n","ax1.semilogy(losses_and_accs[:,4], '-o', label='Test loss')\n","\n","ax2.plot(losses_and_accs[:,1], '-o', label='Train acc')\n","ax2.plot(losses_and_accs[:,3], '-o', label='Valid acc')\n","ax2.plot(losses_and_accs[:,5], '-o', label='Test acc')\n","\n","ax3.plot(sparsity_fracs, '-o', label='Sparsity')\n","\n","for ax in [ax1,ax2,ax3]:\n","    ax.legend()\n","\n","ax2.set_ylim(0.7,1)\n","    \n","print('Final results: ', losses_and_accs[-1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot sparsity fracs\n","plt.plot(sparsity_fracs)\n","print('Final sparsity fraction: ', sparsity_fracs[-1])"],"metadata":{"id":"MJKYUUxQSvMN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["save variables"],"metadata":{"id":"L7OCip10UVCv"}},{"cell_type":"code","source":["import pandas as pd\n","# Train loss\n","# Train acc\n","# Valid loss\n","# Valid acc\n","# Test loss\n","# Test acc\n","# Sparsity\n","x = pd.DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})\n","df = pd.DataFrame({\"Train loss\": losses_and_accs[:,0],\n","           \"Train acc\": losses_and_accs[:,1],\n","           \"Valid loss\": losses_and_accs[:,2],\n","           \"Valid acc\": losses_and_accs[:,3],\n","           \"Test loss\": losses_and_accs[:,4],\n","           \"Test acc\": losses_and_accs[:,5],\n","           \"Sparsity\": sparsity_fracs])\n","df.to_csv(\"ternary_6hidden_relu_softplus.csv\")"],"metadata":{"id":"KgkFPVJUVZ1n"},"execution_count":null,"outputs":[]}]}